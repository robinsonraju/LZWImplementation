{"name":"LZWImplementation","tagline":"","body":"## Welcome \r\nThe objective is to read dictionary-based data compression techniques from David Salomon's \"Data Compression - The Complete Reference\" and to implement the famous LZW algorithm. \r\n\r\nI was hooked on to the book the moment I read the introduction! The book has some great quotes that would make the reader remember certain points while reading and very engaging tone of communication.  \r\nThe last second paragraph in the introduction did bring some smile. On why the name is \"The Complete Reference\", he says as James Joyce used to claim that if Dublin of his time were to be destroyed, it could be reconstructed from his books, substantial part of knowledge about data compression could be reconstructed from this book. viola!\r\n\r\n## Contents of the repository\r\n\r\n### LZWImplementation\r\nJava Implementation of LZW compression algorithm. \r\n\r\n### Canterbury Corpus\r\nThe Canterbury Corpus is a collection of files introduced in 1997 to provide an alternative \r\nto the Calgary corpus for evaluating lossless compression methods. You can read the \"Introduction\" chapter\r\non David Salomon's \"Data Compression - The Complete Reference\" for more details. \r\n\r\n----------------\r\n\r\nIf you want to know high levels concepts of Data compression and dictionary based compression algorithms, read on ..\r\n\r\n## Introduction\r\n\r\nData compression is the process of converting an input data stream (the source stream or the original raw data) into another data stream (the output / bitstream / compressed stream) that has a smaller size. This suggests that there is redundancy in input stream and that by assigning short codes to common events and long codes to rare events, one can create an output that is smaller than the input. Even though redundancy would not be commonplace in a text created by random choice of letters in the alphabet, the fact is that the relatively few files that have redundancy and can be compressed are the ones that we want to compress. They have redundancy, are nonrandom and are therefore useful and interesting. \r\n\r\nKey terms and concepts related to compression are discussed below to give a better understanding of the topic before we go into the details of LZW compression algorithm. \r\nA **nonadaptive** compression method is rigid and does not modify its operations, its parameters, or its tables in response to the particular data being compressed. Such a method is best used to compress data that is all of a single type. \r\n**Lossy/lossless** compression: Certain compression methods are lossy. They achieve better compression by losing some information. When the compressed stream is decompressed, the result is not identical to the original data stream.\r\n**Symmetrical compression** is the case where the compressor and decompressor use basically the same algorithm but work in “opposite” directions.\r\n\r\nThe compression ratio is defined as \r\nCompression Ratio = Size of the output stream / Size of the input stream. \r\n\t \r\nThe inverse of the compression ratio is called the compression factor. \r\n\r\n## Dictionary based data compression\r\nDictionary- based compression methods do not use a statistical model, nor do they use variable-size codes. Instead they select strings of symbols and encode each string as a token using a dictionary. The dictionary holds strings of symbols, and it may be static or dynamic (adaptive). The former is permanent, sometimes allowing the addition of strings but no deletions, whereas the latter holds strings previously found in the input stream, allowing for additions and deletions of strings as new input is being read.\r\n\r\n## LZ77 & LZ78 Compression - Overview \r\n<More details later>\r\nLZ77 and LZ78 are the two lossless data compression algorithms published in papers by Abraham Lempel and Jacob Ziv in 1977 and 1978.  \r\nThey are both theoretically dictionary coders. LZ77 maintains a sliding window during compression. This was later shown to be equivalent to the explicit dictionary constructed by LZ78—however, they are only equivalent when the entire data is intended to be decompressed. LZ78 decompression allows random access to the input as long as the entire dictionary is available while LZ77 decompression must always start at the beginning of the input.\r\n\r\n## LZW Compression\r\n\r\nThis is a variant of LZ78 and was developed by Terry Welch in 1984. It is similar to LZ77 and LZ78 but the main difference is that it doesn’t need the second field of a token. An LZW token is just a pointer to the dictionary. \r\n\r\n### Overview of LZW algorithm \r\nAt a high level, the method consists of initializing the dictionary with codes for known symbols and as new strings are encountered, new codes are added which are later used when these string occur in the input stream. \r\nThe core principle is that the compressor reads one string (x) at a time and searches for it in the dictionary. If the lookup succeeds, the process continues and the next time the string to be searched is the previous string concatenated with the new one (xy). If lookup fails for this, the compressor puts the new string into the dictionary as the next available entry. \r\n\r\n### Example to illustrate LZW\r\nThis can be best illustrated with this example. \r\nWe will use a portion of the example given in “Data Compression – The Complete Reference”1 for the sake of brevity - “sir sid eastman”. We’ll represent space with “_”\r\n\r\nThe steps are as follows:\r\n1.\tInitialize: The dictionary is initialized with the first 256 characters to give codes from 0 to 255. \r\n2.\tProcess “s”: The compressor reads one character at a time and the first one is “s”. The lookup returns true and since it is found, the process continues. \r\n3.\tProcess “si”: The current word/phrase = current character + previous word/phrase found in the dictionary. In the current step, it would be “si” \r\na.\tSince “si” is not found in the dictionary, the compressor does the following – \r\ni.\tOutputs code for s – 115\r\nii.\tStores si as the next entry in the dictionary with code 256.\r\niii.\tSets “prev word” = i\r\n4.\tProcess “i”: The current word/phrase = current char + prev word. In the current step, it would be “ir” \r\na.\tSince “ir” is not found in the dictionary, the compressor does the following – \r\ni.\tOutputs code for i – 105\r\nii.\tStores ir as the next entry in the dictionary with code 257.\r\niii.\tSets “prev word” = r\r\n \r\n5.\tThe process continues. The table below shows all the steps for “sir_sid_eastman”\r\n\r\nx\tIn dictionary\tNew Entry\tOutput\r\ns\tY\t \t \r\nsi\tN\tsi:256\t115(s)\r\ni\tY\t \t \r\nir\tN\tir:257\t105(i)\r\nr\tY\t \t \r\nr_\tN\tr_:258\t114(r )\r\n_\tY\t \t \r\n_s\tN\t_s:259\t32(_)\r\ns\tY\t \t \r\nsi\tY\t \t \r\nsid\tN\tsid:260\t256(si)\r\nd\tY\t \t \r\nd_\tN\td_:261\t100(d)\r\n_\tY\t \t \r\n_e\tN\t_e:262\t32(_)\r\ne\tY\t \t \r\nea\tN\tea:263\t101(e)\r\na\tY\t \t \r\nas\tN\tas:264\t97(a)\r\ns\tY\t \t \r\nst\tN\tst:265\t115(s)\r\nt\tY\t \t \r\ntm\tN\ttm:266\t116(t)\r\nm\tY\t \t \r\nma\tN\tma:267\t109(m)\r\na\tY\t \t \r\nan\tN\tan:268\t97(a)\r\nn\tY\t \t \r\nn_\tN\tn_:269\t110(n)\r\n_\tY\t \t \r\n_eof\tN\t \t32(_)\r\n\r\nThe complete output stream is (only the numbers are output, not the strings in parentheses) as follows:\r\n115 (s), 105 (i), 114 (r), 32 (_), 256 (si), 100 (d), 32 (_), 101 (e), 97 (a), 115 (s), 116 (t), 109 (m), 97 (a), 110 (n), 32(_), eof.\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}